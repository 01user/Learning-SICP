1
00:00:04,970 --> 00:00:06,535
[MUSIC-- "JESU, JOY OF MAN'S DESIRING" BY JOHANN SEBASTIAN BACH]

2
00:00:18,910 --> 00:00:21,275
PROFESSOR: Well, there's one bit of mystery left, 

3
00:00:21,275 --> 00:00:24,440
which I'd like to get rid of right now.

4
00:00:24,440 --> 00:00:30,000
And that's that we've been blithely doing things like cons 

5
00:00:30,000 --> 00:00:32,800
assuming there's always another one.

6
00:00:32,800 --> 00:00:37,025
That we've been doing these things like car-ing and cdr-ing 

7
00:00:37,025 --> 00:00:40,020
and assuming that we had some idea how this can be done.

8
00:00:40,020 --> 00:00:41,075
Now indeed 

9
00:00:41,075 --> 00:00:45,780
we said that that's equivalent to having procedures.

10
00:00:45,780 --> 00:00:47,739
But that doesn't really solve the problem, 

11
00:00:47,739 --> 00:00:51,643
because the procedure need all sorts of complicated mechanisms like environment structures 

12
00:00:51,643 --> 00:00:53,010
and things like that to work.

13
00:00:53,010 --> 00:00:56,700
And those were ultimately made out of conses in the model that we had, 

14
00:00:56,700 --> 00:00:59,380
so that really doesn't solve the problem.

15
00:00:59,380 --> 00:01:04,760
Now the problem here is the glue the data structure's made out of.

16
00:01:04,760 --> 00:01:07,370
What kind of possible thing could it be?

17
00:01:07,370 --> 00:01:10,460
We've been showing you things like a machine, 

18
00:01:10,460 --> 00:01:14,275
a computer that has a controller, 

19
00:01:14,275 --> 00:01:16,980
and some registers, and maybe a stack.

20
00:01:16,980 --> 00:01:18,875
And we haven't said anything about, 

21
00:01:18,875 --> 00:01:20,570
for example, larger memory.

22
00:01:20,570 --> 00:01:23,740
And I think that's what we have to worry about right now.

23
00:01:23,740 --> 00:01:28,800
But just to make it perfectly clear that this is an inessential, 

24
00:01:28,800 --> 00:01:31,100
purely implementational thing, 

25
00:01:31,100 --> 00:01:32,600
I'd like to show you, for example, 

26
00:01:32,600 --> 00:01:34,800
how you can do it all with the numbers.

27
00:01:34,800 --> 00:01:37,590
That's an easy one.

28
00:01:37,590 --> 00:01:39,343
Famous fellow by the name of Godel, 

29
00:01:39,343 --> 00:01:46,255
a logician at the end of the 1930s, 

30
00:01:46,255 --> 00:01:54,320
invented a very clever way of encoding the complicated expressions as numbers.

31
00:01:54,320 --> 00:01:55,050
For example-- 

32
00:01:55,050 --> 00:01:58,000
I'm not saying exactly what Godel's scheme is, 

33
00:01:58,000 --> 00:01:59,660
because he didn't use words like cons.

34
00:01:59,660 --> 00:02:03,090
He had other kinds of ways of combining to make expressions.

35
00:02:03,090 --> 00:02:07,920
But he said, I'm going to assign a number to every algebraic expression.

36
00:02:07,920 --> 00:02:09,725
And the way I'm going to manufacture these numbers 

37
00:02:09,725 --> 00:02:12,470
is by combining the numbers of the parts.

38
00:02:12,470 --> 00:02:13,625
So for example, 

39
00:02:13,625 --> 00:02:15,350
what we were doing our world, 

40
00:02:15,350 --> 00:02:30,675
we could say that if objects are represented by numbers, 

41
00:02:30,675 --> 00:02:38,229
then cons of x and y 

42
00:02:38,229 --> 00:02:46,130
could be represented by 2 to the x times 2 to the y.

43
00:02:46,130 --> 00:02:49,560
Because then we could extract the parts.

44
00:02:49,560 --> 00:02:51,100
We could say, for example, 

45
00:02:51,100 --> 00:03:06,690
that then car of, say, x is the number of factors of 2 in x. 

46
00:03:06,690 --> 00:03:10,690
And of course cdr is the same thing.

47
00:03:10,690 --> 00:03:16,510
It's the number of factors of 3 in x.

48
00:03:16,510 --> 00:03:19,100
Now this is a perfectly reasonable scheme, 

49
00:03:19,100 --> 00:03:22,800
except for the fact that the numbers rapidly get to be much lar ger  

50
00:03:22,800 --> 00:03:27,950
in number of digits than the number of protons in the universe.

51
00:03:27,950 --> 00:03:33,430
So there's no easy way to use this scheme other than the theoretical one.

52
00:03:33,430 --> 00:03:35,125
On the other hand, 

53
00:03:35,125 --> 00:03:38,450
there are other ways of representing these things.

54
00:03:38,450 --> 00:03:43,325
We have been thinking in terms of little boxes.

55
00:03:43,325 --> 00:03:46,500
We've been thinking about our cons structures 

56
00:03:46,500 --> 00:03:50,280
as looking sort of like this.

57
00:03:50,280 --> 00:03:53,610
They're little pigeon holes with things in them.

58
00:03:53,610 --> 00:03:57,210
And of course we arrange them in little trees.

59
00:03:57,210 --> 00:04:02,700
I wish that the semiconductor manufacturers would supply me with something appropriate for this, 

60
00:04:02,700 --> 00:04:03,850
but actually 

61
00:04:03,850 --> 00:04:09,380
what they do supply me with is a linear memory.

62
00:04:09,380 --> 00:04:15,075
Memory is sort of a big pile of pigeonholes, 

63
00:04:15,075 --> 00:04:17,720
pigeonholes like this.

64
00:04:17,720 --> 00:04:21,000
Each of which can hold a certain sized object, 

65
00:04:21,000 --> 00:04:23,390
a fixed size object.

66
00:04:23,390 --> 00:04:24,075
So, for example, 

67
00:04:24,075 --> 00:04:28,550
a complicated list with 25 elements won't fit in one of these.

68
00:04:28,550 --> 00:04:32,275
However, each of these is indexed by an address.

69
00:04:33,970 --> 00:04:38,060
So the address might be zero here, one here, two here, three here, and so on.

70
00:04:38,060 --> 00:04:40,400
That we write these down as numbers is unimportant.

71
00:04:40,400 --> 00:04:41,950
What matters is that they're distinct 

72
00:04:41,950 --> 00:04:44,970
as a way to get to the next one.

73
00:04:44,970 --> 00:04:46,366
And inside of each of these,

74
00:04:46,366 --> 00:04:49,530
 we can stuff something into these pigeonholes.

75
00:04:49,530 --> 00:04:51,025
That's what memory is like, 

76
00:04:51,025 --> 00:04:54,150
for those of you who haven't built a computer.

77
00:04:56,690 --> 00:05:00,425
Now the problem is how are we going to impose on this type of structure, 

78
00:05:00,425 --> 00:05:03,290
this nice tree structure.

79
00:05:03,290 --> 00:05:04,575
Well it's not very hard, 

80
00:05:04,575 --> 00:05:06,630
and there have been numerous schemes involved in this.

81
00:05:06,630 --> 00:05:08,800
The most important one is to say, 

82
00:05:08,800 --> 00:05:13,151
well assuming that the semiconductor manufacturer allows me to arrange 

83
00:05:13,151 --> 00:05:16,287
my memory so that one of these pigeonholes is big enough 

84
00:05:16,287 --> 00:05:22,050
to hold the address of another I haven't made.

85
00:05:22,050 --> 00:05:23,700
Now it actually has to be a little bit bigger 

86
00:05:23,700 --> 00:05:27,650
because I have to also install or store some information 

87
00:05:27,650 --> 00:05:30,390
as to a tag which describes the kind of thing that's there.

88
00:05:30,390 --> 00:05:32,625
And we'll see that in a second.

89
00:05:32,625 --> 00:05:36,081
And of course if the semiconductor manufacturer doesn't arrange it so I can do that, 

90
00:05:36,081 --> 00:05:43,770
then of course I can, with some cleverness, arrange combinations of these to fit together in that way.

91
00:05:43,770 --> 00:05:51,740
So we're going to have to imagine imposing this complicated tree structure on our nice linear memory.

92
00:05:51,740 --> 00:05:54,475
If we look at the first still store, 

93
00:05:54,475 --> 00:05:59,490
we see a classic scheme for doing that.

94
00:05:59,490 --> 00:06:06,275
It's a standard way of representing Lisp structures in a linear memory.

95
00:06:06,275 --> 00:06:12,030
What we do is we divide this memory into two parts.

96
00:06:12,030 --> 00:06:14,450
An array called the cars, 

97
00:06:14,450 --> 00:06:17,580
and an array called the cdrs.

98
00:06:17,580 --> 00:06:21,275
Now whether those happen to be sequential addresses or whatever, 

99
00:06:21,275 --> 00:06:22,875
it's not important.

100
00:06:22,875 --> 00:06:25,800
That's somebody's implementation details.

101
00:06:25,800 --> 00:06:28,960
But there are two arrays here.

102
00:06:28,960 --> 00:06:34,840
Linear arrays indexed by sequential indices like this.

103
00:06:34,840 --> 00:06:37,467
What is stored in each of these pigeonholes 

104
00:06:37,467 --> 00:06:41,430
is a typed object.

105
00:06:41,430 --> 00:06:42,575
And what we have here 

106
00:06:42,575 --> 00:06:47,790
are types which begin with letters like p, standing for a pair.

107
00:06:47,790 --> 00:06:50,040
Or n, standing for a number.

108
00:06:50,040 --> 00:06:54,813
Or e, standing for an empty list. 

109
00:06:54,813 --> 00:06:57,025
The end of the list. 

110
00:06:57,025 --> 00:07:00,050
And so if we wish to represent an object like this, 

111
00:07:00,050 --> 00:07:02,650
the list beginning with 1, 2 

112
00:07:02,650 --> 00:07:06,430
and then having a 3 and a 4 as its second and third elements.

113
00:07:06,430 --> 00:07:09,350
A list containing a list as its first part 

114
00:07:09,350 --> 00:07:12,870
and then two numbers as a second and third parts.

115
00:07:12,870 --> 00:07:17,320
Then of course we draw it sort of like this these days, in box-and-pointer notation.

116
00:07:17,320 --> 00:07:18,000
And you see, 

117
00:07:18,000 --> 00:07:22,275
these are the three cells that have as their car pointer 

118
00:07:22,275 --> 00:07:28,390
the object which is either 1, 2 or 3 or 4.

119
00:07:28,390 --> 00:07:29,750
And then of course the 1, 2, 

120
00:07:29,750 --> 00:07:31,325
the car of this entire structure, 

121
00:07:31,325 --> 00:07:35,940
is itself a substructure which contains a sublist like that.

122
00:07:35,940 --> 00:07:37,200
What I'm about to do 

123
00:07:37,200 --> 00:07:41,880
is put down places which are-- I'm going to assign indices.

124
00:07:41,880 --> 00:07:43,562
Like this 1, over here, 

125
00:07:43,562 --> 00:07:46,850
represents the index of this cell.

126
00:07:49,850 --> 00:07:52,375
But that pointer that we see here 

127
00:07:52,375 --> 00:07:57,400
is a reference to the pair of pigeonholes in the cars and the cdrs 

128
00:07:57,400 --> 00:08:02,000
that are labeled by 1 in my linear memory down here.

129
00:08:02,000 --> 00:08:05,850
So if I wish to impose this structure on my linear memory, 

130
00:08:05,850 --> 00:08:12,220
what I do is I say, oh yes, why don't we drop this into cell 1?

131
00:08:12,220 --> 00:08:12,660
I pick one.

132
00:08:12,660 --> 00:08:14,270
There's 1.

133
00:08:14,270 --> 00:08:16,225
And that says that its car, 

134
00:08:16,225 --> 00:08:17,950
I'm going to assign it to be a pair.

135
00:08:17,950 --> 00:08:22,590
It's a pair,  which is in index 5. 

136
00:08:22,590 --> 00:08:25,390
And the cdr, which is this one over here, 

137
00:08:25,390 --> 00:08:28,340
is a pair which I'm going to stick into place 2.

138
00:08:28,340 --> 00:08:30,890
p2.

139
00:08:30,890 --> 00:08:32,950
And take a look at p2.

140
00:08:32,950 --> 00:08:39,520
Oh yes, well p2 is a thing whose car is the number 3, so as you see, an n3.

141
00:08:39,520 --> 00:08:41,727
And whose cdr, over here, 

142
00:08:41,727 --> 00:08:46,640
is a pair, which lives in place 4.

143
00:08:46,640 --> 00:08:48,650
So that's what this p4 is.

144
00:08:48,650 --> 00:08:54,475
p4 is a number whose value is 4 in its car 

145
00:08:54,475 --> 00:08:59,170
and whose cdr is an empty list right there.

146
00:08:59,170 --> 00:09:00,690
And that ends it.

147
00:09:00,690 --> 00:09:04,907
So this is the traditional way of representing 

148
00:09:04,907 --> 00:09:11,620
this kind of binary tree in a linear memory.

149
00:09:11,620 --> 00:09:15,100
Now the next question, of course, 

150
00:09:15,100 --> 00:09:18,440
that we might want to worry about is just a little bit of implementation.

151
00:09:18,440 --> 00:09:23,625
That means that when I write procedures of the form assigned a, 

152
00:09:23,625 --> 00:09:30,140
[UNINTELLIGIBLE] procedures-- lines of register machine code of the form assigned a, the car of [UNINTELLIGIBLE]

153
00:09:30,140 --> 00:09:31,975
b, what I really mean 

154
00:09:31,975 --> 00:09:38,740
is addressing these elements.

155
00:09:38,740 --> 00:09:44,470
And so we're going to think of that as a abbreviation for it.

156
00:09:44,470 --> 00:09:46,600
Now of course in order to write that down 

157
00:09:46,600 --> 00:09:49,140
I'm going to introduce some sort of a structure called a vector.

158
00:09:52,120 --> 00:09:56,840
And we're going to have something which will reference a vector, 

159
00:09:56,840 --> 00:09:58,710
just so we can write it down.

160
00:09:58,710 --> 00:10:01,025
Which takes the name of the vector, 

161
00:10:01,025 --> 00:10:03,970
or the-- I don't think that name is the right word.

162
00:10:03,970 --> 00:10:11,201
Which takes the vector and the index, 

163
00:10:11,201 --> 00:10:14,657
and I have to have a way of setting one of those with something called a vector set, 

164
00:10:14,657 --> 00:10:16,280
I don't really care.

165
00:10:16,280 --> 00:10:18,113
But let's look, for example, 

166
00:10:18,113 --> 00:10:26,470
at then that kind of implementation of car and cdr.

167
00:10:26,470 --> 00:10:31,150
So for example if I happen to have a register b, 

168
00:10:31,150 --> 00:10:35,950
which contains the type index of a pair, 

169
00:10:35,950 --> 00:10:39,350
and therefore it is the pointer to a pair, 

170
00:10:39,350 --> 00:10:44,490
then I could take the car of that and if I-- write this down-- I might put that in register a.

171
00:10:44,490 --> 00:10:47,375
What that really is is a representation of 

172
00:10:47,375 --> 00:10:50,191
the assign to a, 

173
00:10:50,191 --> 00:10:55,425
the value of vector reffing-- or array indexing, if you will-- or something, 

174
00:10:55,425 --> 00:11:02,650
the cars object-- whatever that is-- with the index, b.

175
00:11:02,650 --> 00:11:04,100
And similarly for cdr. 

176
00:11:04,100 --> 00:11:09,092
And we can do the same thing for assignment to data structures, 

177
00:11:09,092 --> 00:11:11,840
if we need to do that sort of thing at all.

178
00:11:11,840 --> 00:11:14,580
It's not too hard to build that.

179
00:11:14,580 --> 00:11:18,010
Well now the next question is how are we going to do allocation.

180
00:11:18,010 --> 00:11:21,550
And every so often I say I want a cons.

181
00:11:21,550 --> 00:11:23,790
Now conses don't grow on trees.

182
00:11:23,790 --> 00:11:25,340
Or maybe they should.

183
00:11:25,340 --> 00:11:29,980
But I have to have some way of getting the next one.

184
00:11:29,980 --> 00:11:31,475
I have to have some idea of 

185
00:11:31,475 --> 00:11:35,630
if their memory is unused that I might want to allocate from.

186
00:11:35,630 --> 00:11:37,380
And there are many schemes for doing this.

187
00:11:37,380 --> 00:11:42,100
And the particular thing I'm showing you right now is not essential.

188
00:11:42,100 --> 00:11:44,960
However it's convenient and has been done many times.

189
00:11:44,960 --> 00:11:47,660
One scheme's was called the free list allocation scheme.

190
00:11:47,660 --> 00:11:48,684
What that means is 

191
00:11:48,684 --> 00:11:51,550
that all of the free memory that there is in the world 

192
00:11:51,550 --> 00:11:54,550
is linked together in a linked list, 

193
00:11:54,550 --> 00:11:56,960
just like all the other stuff.

194
00:11:56,960 --> 00:12:00,950
And whenever you need a free cell to make a new cons, 

195
00:12:00,950 --> 00:12:04,325
you grab the first, one make the free list be the cdr of it, 

196
00:12:04,325 --> 00:12:06,030
and then allocate that.

197
00:12:06,030 --> 00:12:09,530
And so what that looks like is something like this.

198
00:12:09,530 --> 00:12:18,510
Here we have the free list starting in 6.

199
00:12:18,510 --> 00:12:24,860
And what that is is a pointer-off to say 8.

200
00:12:24,860 --> 00:12:28,870
So what it says is, this one is free and the next one is an 8.

201
00:12:28,870 --> 00:12:32,271
This one is free and the next one is in 3, 

202
00:12:32,271 --> 00:12:33,930
the next one that's free.

203
00:12:33,930 --> 00:12:37,680
That one's free and the next one is in 0.

204
00:12:37,680 --> 00:12:40,940
That one's free and the next one's in 15.

205
00:12:40,940 --> 00:12:42,780
Something like that.

206
00:12:42,780 --> 00:12:46,400
We can imagine having such a structure.

207
00:12:46,400 --> 00:12:49,450
Given that we have something like that, 

208
00:12:49,450 --> 00:12:53,940
then it's possible to just get one when you need it.

209
00:12:53,940 --> 00:12:57,450
And so a program for doing cons, 

210
00:12:57,450 --> 00:12:59,320
this is what cons might turn into.

211
00:12:59,320 --> 00:13:06,200
To assign to a register A the result of cons-ing, a B onto C, 

212
00:13:06,200 --> 00:13:09,275
the value in this containing B and the value containing C,

213
00:13:09,275 --> 00:13:12,475
 what we have to do is get the current [? type ?] ahead of the freelist, 

214
00:13:12,475 --> 00:13:15,643
make the free list be its cdr. 

215
00:13:15,643 --> 00:13:20,475
Then we have to change the cars to be the thing we're 

216
00:13:20,475 --> 00:13:25,900
making up to be in A to be the B, the thing in B.

217
00:13:25,900 --> 00:13:33,200
And we have to make change the cdrs of the thing that's in A to be C. 

218
00:13:33,200 --> 00:13:36,650
And then what we have in A is the right new frob, whatever it is.

219
00:13:36,650 --> 00:13:40,470
The object that we want.

220
00:13:40,470 --> 00:13:43,975
Now there's a little bit of a cheat here that I haven't told you about, 

221
00:13:43,975 --> 00:13:48,455
which is somewhere around here I haven't set that

222
00:13:48,455 --> 00:13:53,510
 I've the type of the thing that I'm cons-ing up to be a pair, and I ought to.

223
00:13:53,510 --> 00:13:55,675
So there should be some sort of bits here are being set, 

224
00:13:55,675 --> 00:13:59,810
and I just haven't written that down.

225
00:13:59,810 --> 00:14:03,100
We could have arranged it, of course, for the free lift to be made out of pairs.

226
00:14:03,100 --> 00:14:06,430
And so then there's no problem with that.

227
00:14:06,430 --> 00:14:10,225
But that sort of-- again, an inessential detail in a way 

228
00:14:10,225 --> 00:14:17,540
some particular programmer or architect or whatever might manufacture his machine or Lisp system.

229
00:14:17,540 --> 00:14:23,550
So for example, just looking at this, to allocate

230
00:14:23,550 --> 00:14:27,125
 given that I had already the structure that you saw before, 

231
00:14:27,125 --> 00:14:30,559
supposing I wanted to allocate a new cell, 

232
00:14:30,559 --> 00:14:37,300
which is going to be representation of list one, one, two, 

233
00:14:37,300 --> 00:14:43,430
where already one two was the car of the list we were playing with before.

234
00:14:43,430 --> 00:14:44,780
Well that's not so hard.

235
00:14:44,780 --> 00:14:46,200
I stored that one and one, 

236
00:14:46,200 --> 00:14:49,530
so p1 one is the representation of this.

237
00:14:49,530 --> 00:14:51,690
This is p5.

238
00:14:51,690 --> 00:14:54,070
That's going to be the cdr of this.

239
00:14:54,070 --> 00:14:55,525
Now we're going to pull something off the free list, 

240
00:14:55,525 --> 00:14:57,780
but remember the free list started at six.

241
00:14:57,780 --> 00:15:00,600
The new free list after this allocation is eight, 

242
00:15:00,600 --> 00:15:02,890
a free list beginning at eight.

243
00:15:02,890 --> 00:15:06,157
And of course in six now we have a number one, 

244
00:15:06,157 --> 00:15:13,330
which is what we wanted, with its cdr being the pair starting in location five.

245
00:15:13,330 --> 00:15:16,810
And that's no big deal.

246
00:15:16,810 --> 00:15:21,000
So the only problem really remaining here is, 

247
00:15:21,000 --> 00:15:25,080
well, I don't have an infinitely large memory.

248
00:15:25,080 --> 00:15:27,250
If I do this for a little while,

249
00:15:27,250 --> 00:15:30,600
 say, for example, supposing it takes me a microsecond to do a cons, 

250
00:15:30,600 --> 00:15:33,600
and I have a million cons memory 

251
00:15:33,600 --> 00:15:35,950
then I'm only going to run out in a second, 

252
00:15:35,950 --> 00:15:38,000
and that's pretty bad.

253
00:15:38,000 --> 00:15:40,625
So what we do to prevent that disaster, 

254
00:15:40,625 --> 00:15:42,600
that ecological disaster, 

255
00:15:42,600 --> 00:15:44,300
talk about right after questions.

256
00:15:44,300 --> 00:15:45,550
Are there any questions?

257
00:15:51,500 --> 00:15:52,030
Yes.

258
00:15:52,030 --> 00:15:54,675
AUDIENCE: In the environment diagrams that we were drawing 

259
00:15:54,675 --> 00:15:58,250
we would use the body of procedures, 

260
00:15:58,250 --> 00:16:04,930
and you would eventually wind up with things that were no longer useful in that structure.

261
00:16:04,930 --> 00:16:06,890
How is that represented?

262
00:16:06,890 --> 00:16:09,180
PROFESSOR: There's two problems here.

263
00:16:09,180 --> 00:16:13,870
One you were asking is that material becomes useless.

264
00:16:13,870 --> 00:16:14,920
We'll talk about that in a second.

265
00:16:14,920 --> 00:16:18,100
That has to do with how to prevent ecological disasters.

266
00:16:18,100 --> 00:16:21,820
If I make a lot of garbage I have to somehow be able to clean up after myself.

267
00:16:21,820 --> 00:16:23,430
And we'll talk about that in a second.

268
00:16:23,430 --> 00:16:27,210
The other question you're asking is how you represent the environments, I think.

269
00:16:27,210 --> 00:16:27,600
AUDIENCE: Yes.

270
00:16:27,600 --> 00:16:28,190
PROFESSOR: OK.

271
00:16:28,190 --> 00:16:30,860
And the environment structures can be represented in arbitrary ways.

272
00:16:30,860 --> 00:16:31,780
There are lots of them.

273
00:16:31,780 --> 00:16:33,630
I mean, here I'm just telling you about list cells.

274
00:16:33,630 --> 00:16:36,725
Of course every real system has vectors of arbitrary length 

275
00:16:36,725 --> 00:16:41,080
as well as the vectors of length, too, which represent list cells.

276
00:16:41,080 --> 00:16:47,300
And the environment structures that one uses in a professionally written Lisp system

277
00:16:47,300 --> 00:16:55,350
 tend to be vectors which contain a number of elements approximately equal to the number of arguments-- a little bit more 

278
00:16:55,350 --> 00:16:58,290
because you need certain glue.

279
00:16:58,290 --> 00:17:00,360
So remember, the environment [UNINTELLIGIBLE]

280
00:17:00,360 --> 00:17:00,740
frames.

281
00:17:00,740 --> 00:17:03,980
The frames are constructed by applying a procedure.

282
00:17:03,980 --> 00:17:06,825
In doing so, an allocation is made of 

283
00:17:06,825 --> 00:17:11,270
a place which is the number of arguments long plus [? unglue ?]

284
00:17:11,270 --> 00:17:13,859
that gets linked into a chain.

285
00:17:13,859 --> 00:17:15,660
It's just like algol at that level.

286
00:17:19,810 --> 00:17:21,060
There any other questions?

287
00:17:23,700 --> 00:17:23,920
OK.

288
00:17:23,920 --> 00:17:26,106
Thank you, and let's take a short break.

289
00:17:26,106 --> 00:17:27,699
[MUSIC-- "JESU, JOY OF MAN'S DESIRING" BY JOHANN SEBASTIAN BACH]

290
00:18:12,270 --> 00:18:14,550
PROFESSOR: Well, as I just said, 

291
00:18:14,550 --> 00:18:19,420
computer memories supplied by the semiconductor manufacturers are finite.

292
00:18:19,420 --> 00:18:21,620
And that's quite a pity.

293
00:18:21,620 --> 00:18:24,030
It might not always be that way.

294
00:18:24,030 --> 00:18:28,860
Just for a quick calculation, you can see that it's possible that if [? memory ?]

295
00:18:28,860 --> 00:18:31,225
prices keep going at the rate they're going 

296
00:18:31,225 --> 00:18:34,425
that if you still took a microsecond second to do a cons, 

297
00:18:34,425 --> 00:18:39,450
then-- first of all, everybody should know that there's about pi times ten to the seventh seconds in a year.

298
00:18:39,450 --> 00:18:43,940
And so that would be ten to the seventh plus ten to the sixth is ten to the thirteenth.

299
00:18:43,940 --> 00:18:47,520
So there's maybe ten to the fourteenth conses in the life of a machine.

300
00:18:47,520 --> 00:18:51,200
If there was ten to the fourteenth words of memory on your machine, 

301
00:18:51,200 --> 00:18:54,020
you'd never run out.

302
00:18:54,020 --> 00:18:56,310
And that's not completely unreasonable.

303
00:18:56,310 --> 00:18:58,460
Ten to the fourteenth is not a very large number.

304
00:19:03,860 --> 00:19:05,180
I don't think it is.

305
00:19:05,180 --> 00:19:08,700
But then again I like to play with astronomy.

306
00:19:08,700 --> 00:19:12,930
It's at least ten to the eighteenth centimeters between us and the nearest star.

307
00:19:12,930 --> 00:19:19,150
But the thing I'm about to worry about  is, 

308
00:19:19,150 --> 00:19:21,275
at least in the current economic state of affairs, 

309
00:19:21,275 --> 00:19:24,200
ten to the fourteenth pieces of memory is expensive. 

310
00:19:24,200 --> 00:19:28,120
And so I suppose what we have to do is make do with much smaller memories.

311
00:19:28,120 --> 00:19:35,800
Now in general we want to have an illusion of infinity.

312
00:19:35,800 --> 00:19:37,825
All we need to do is arrange it 

313
00:19:37,825 --> 00:19:40,100
so that whenever you look, the thing is there.

314
00:19:42,670 --> 00:19:45,105
That's really an important idea.

315
00:19:49,540 --> 00:19:52,325
A person or a computer lives only a finite amount of time 

316
00:19:52,325 --> 00:19:55,280
and can only take a finite number of looks at something.

317
00:19:55,280 --> 00:19:58,190
And so you really only need a finite amount of stuff.

318
00:19:58,190 --> 00:20:00,773
But you have to arrange it so no matter how much there is, 

319
00:20:00,773 --> 00:20:03,461
how much you really claim there is, 

320
00:20:03,461 --> 00:20:06,900
there's always enough stuff so that when you take a look, it's there.

321
00:20:06,900 --> 00:20:08,750
And so you only need a finite amount.

322
00:20:08,750 --> 00:20:11,630
But let's see.

323
00:20:11,630 --> 00:20:13,925
One problem is, as was brought up, 

324
00:20:13,925 --> 00:20:16,425
that there are possible ways 

325
00:20:16,425 --> 00:20:19,410
that there is lots of stuff that we make that we don't need.

326
00:20:19,410 --> 00:20:22,760
And we could recycle the material out of which its made.

327
00:20:22,760 --> 00:20:24,150
An example 

328
00:20:24,150 --> 00:20:28,400
is the fact that we're building environment structures, 

329
00:20:28,400 --> 00:20:30,470
and we do so every time we call a procedure.

330
00:20:30,470 --> 00:20:32,810
We have built in it a environment frame.

331
00:20:32,810 --> 00:20:36,730
That environment frame doesn't necessarily have a very long lifetime.

332
00:20:36,730 --> 00:20:39,425
Its lifetime, meaning its usefulness, 

333
00:20:39,425 --> 00:20:42,850
may exist only over the invocation of the procedure.

334
00:20:42,850 --> 00:20:46,875
Or if the procedure exports another procedure by returning it as a value 

335
00:20:46,875 --> 00:20:48,525
and that procedure is defined inside of it, 

336
00:20:48,525 --> 00:20:53,500
well then the lifetime of the frame of the outer procedure still is 

337
00:20:53,500 --> 00:20:58,530
only the lifetime of the procedure which was exported.

338
00:20:58,530 --> 00:21:01,960
And so ultimately, a lot of that is garbage.

339
00:21:01,960 --> 00:21:05,370
There are other ways of producing garbage as well.

340
00:21:05,370 --> 00:21:07,240
Users produce garbage.

341
00:21:07,240 --> 00:21:10,930
An example of user garbage is something like this.

342
00:21:10,930 --> 00:21:14,000
If we write a program to, for example,

343
00:21:14,000 --> 00:21:16,050
 append two lists together, 

344
00:21:16,050 --> 00:21:18,325
well one way to do it is 

345
00:21:18,325 --> 00:21:21,375
to reverse the first list onto the empty list 

346
00:21:21,375 --> 00:21:24,703
and reverse that onto the second list. 

347
00:21:24,703 --> 00:21:28,160
Now that's not terribly bad way of doing it.

348
00:21:28,160 --> 00:21:33,875
And however, the intermediate result, which is the reversal of the first list 

349
00:21:33,875 --> 00:21:36,700
as done by this program, 

350
00:21:36,700 --> 00:21:41,010
is never going to be accessed ever again after it's copied back on to the second.

351
00:21:41,010 --> 00:21:43,580
It's an intermediate result.

352
00:21:43,580 --> 00:21:46,075
It's going to be hard to ever see 

353
00:21:46,075 --> 00:21:48,600
how anybody would ever be able to access it.

354
00:21:48,600 --> 00:21:51,050
In fact, it will go away.

355
00:21:51,050 --> 00:21:52,900
Now if we make a lot of garbage like that, 

356
00:21:52,900 --> 00:21:54,800
and we should be allowed to, 

357
00:21:54,800 --> 00:21:58,800
then there's got to be some way to reclaim that garbage.

358
00:21:58,800 --> 00:22:04,325
Well, what I'd like to tell you about now is a very clever technique

359
00:22:04,325 --> 00:22:17,410
 whereby a Lisp system can prove a small theorem every so often on the [? forum, ?] the following piece of junk will never be accessed again.

360
00:22:17,410 --> 00:22:21,400
It can have no affect on the future of the computation.

361
00:22:21,400 --> 00:22:24,920
It's actually based on a very simple idea.

362
00:22:24,920 --> 00:22:28,950
We've designed our computers to look sort of like this.

363
00:22:28,950 --> 00:22:35,280
There's some data path, which contains the registers.

364
00:22:35,280 --> 00:22:42,610
There are things like x, and env, and val, and so on.

365
00:22:42,610 --> 00:22:46,069
And there's one here called stack, 

366
00:22:46,069 --> 00:22:50,240
some sort which points off to a structure somewhere, which is the stack.

367
00:22:50,240 --> 00:22:51,740
And we'll worry about that in a second.

368
00:22:51,740 --> 00:22:54,389
There's some finite controller, 

369
00:22:54,389 --> 00:22:56,730
finite state machine controller.

370
00:22:56,730 --> 00:22:59,800
And there's some control signals that go this way and 

371
00:22:59,800 --> 00:23:03,350
predicate results that come this way, not the interesting part.

372
00:23:03,350 --> 00:23:06,806
There's some sort of structured memory, 

373
00:23:06,806 --> 00:23:10,460
which I just told you how to make, which may contain a stack.

374
00:23:10,460 --> 00:23:13,450
I didn't tell you how to make things of arbitrary shape, only pairs.

375
00:23:13,450 --> 00:23:17,775
But in fact with what I've told you can simulate a stack by a big list. 

376
00:23:17,775 --> 00:23:20,360
I don't plan to do that, it's not a nice way to do it.

377
00:23:20,360 --> 00:23:22,990
But we could have something like that.

378
00:23:22,990 --> 00:23:25,647
We have all sorts of little data structures in here t

379
00:23:25,647 --> 00:23:27,470
hat are hooked together in funny ways.

380
00:23:30,115 --> 00:23:32,560
They connect to other things.

381
00:23:32,560 --> 00:23:33,250
And so on.

382
00:23:33,250 --> 00:23:37,190
And ultimately things up there are pointers to these.

383
00:23:37,190 --> 00:23:39,407
The things that are in the registers 

384
00:23:39,407 --> 00:23:44,910
are pointers off to the data structures that live in this Lisp structure memory.

385
00:23:44,910 --> 00:23:51,055
Now the truth of the matter is 

386
00:23:51,055 --> 00:23:55,550
that the entire consciousness of this machine is in these registers.

387
00:23:55,550 --> 00:23:58,750
There is no possible way that the machine,

388
00:23:58,750 --> 00:24:01,374
 if done correctly, if built correctly, 

389
00:24:01,374 --> 00:24:04,575
can access anything in this Lisp structure memory 

390
00:24:04,575 --> 00:24:08,095
unless the thing in that Lisp structure memory

391
00:24:08,095 --> 00:24:15,070
is connected by a sequence of data structures to the registers.

392
00:24:15,070 --> 00:24:19,088
If it's accessible by legitimate data structure selectors 

393
00:24:19,088 --> 00:24:22,280
from the pointers that are stored in these registers.

394
00:24:22,280 --> 00:24:24,940
Things like array references, perhaps.

395
00:24:24,940 --> 00:24:28,790
Or cons cell references, cars and cdrs.

396
00:24:28,790 --> 00:24:32,740
But I can't just talk about a random place in this memory, because I can't get to it.

397
00:24:32,740 --> 00:24:37,008
These are being arbitrary names I'm not allowed to count, 

398
00:24:37,008 --> 00:24:38,985
at least as I'm evaluating expressions.

399
00:24:41,620 --> 00:24:43,275
If that's the case 

400
00:24:43,275 --> 00:24:47,160
then there's a very simple theorem to be proved.

401
00:24:47,160 --> 00:24:47,900
Which is,

402
00:24:47,900 --> 00:24:51,164
if I start with all lead pointers that are in all these registers 

403
00:24:51,164 --> 00:24:52,825
and recursively chase out, 

404
00:24:52,825 --> 00:24:56,900
marking all the places I can get to by selectors, 

405
00:24:56,900 --> 00:25:00,750
then eventually I mark everything they can be gotten to.

406
00:25:00,750 --> 00:25:05,560
Anything which is not so marked is garbage and can be recycled.

407
00:25:05,560 --> 00:25:07,200
Very simple.

408
00:25:07,200 --> 00:25:11,180
Cannot affect the future of the computation.

409
00:25:11,180 --> 00:25:16,616
So let me show you that in a particular example.

410
00:25:17,124 --> 00:25:23,640
Now that means I'm going to have to append to my description of the list structure a mark.

411
00:25:23,640 --> 00:25:29,080
And so here, for example, is a Lisp structured memory.

412
00:25:29,080 --> 00:25:31,333
And in this Lisp structured memory is a Lisp structure 

413
00:25:31,333 --> 00:25:35,875
beginning in a place I'm going to call-- 

414
00:25:35,875 --> 00:25:38,590
this is the root.

415
00:25:38,590 --> 00:25:40,120
Now it doesn't really have to have a root.

416
00:25:40,120 --> 00:25:42,670
It could be a bunch of them, like all the registers.

417
00:25:42,670 --> 00:25:44,138
But I could cleverly arrange it 

418
00:25:44,138 --> 00:25:46,300
so all the registers, all the things that are in old registers 

419
00:25:46,300 --> 00:25:50,460
are also at the right moment put into this root structure, 

420
00:25:50,460 --> 00:25:51,850
and then we've got one pointer to it.

421
00:25:51,850 --> 00:25:54,570
I don't really care.

422
00:25:54,570 --> 00:25:58,720
So the idea is we're going to cons up stuff until our free list is empty.

423
00:25:58,720 --> 00:26:00,950
We've run out of things.

424
00:26:00,950 --> 00:26:04,475
Now we're going to do this process of proving the theorem 

425
00:26:04,475 --> 00:26:07,850
that a certain percentage of the memory has got crap in it.

426
00:26:07,850 --> 00:26:09,787
And then we're going to recycle that 

427
00:26:09,787 --> 00:26:14,570
to grow new trees, a standard use of such garbage.

428
00:26:17,090 --> 00:26:18,840
So in any case, what do we have here?

429
00:26:18,840 --> 00:26:24,275
Well we have some data structure which starts out over  here in p5. 

430
00:26:25,150 --> 00:26:26,750
and it will start at one

431
00:26:27,275 --> 00:26:33,980
And in fact it has a car in p5, and its cdr is in two.

432
00:26:33,980 --> 00:26:36,700
And all the marks start out at zero.

433
00:26:36,700 --> 00:26:39,920
Well let's start marking, just to play this game.

434
00:26:39,920 --> 00:26:42,540
OK.

435
00:26:42,540 --> 00:26:44,475
So for example, 

436
00:26:44,475 --> 00:26:48,390
since I can access one from the root I will mark that.

437
00:26:48,390 --> 00:26:50,960
Let me mark it.

438
00:26:50,960 --> 00:26:52,430
Bang.

439
00:26:52,430 --> 00:26:54,560
That's marked.

440
00:26:54,560 --> 00:26:59,025
Now since I have a five here I can go to five

441
00:26:59,025 --> 00:27:01,450
 and see, well I'll mark that.

442
00:27:01,450 --> 00:27:01,760
Bang.

443
00:27:01,760 --> 00:27:02,900
That's useful stuff.

444
00:27:02,900 --> 00:27:05,275
But five references as a number in its car, 

445
00:27:05,275 --> 00:27:08,700
I'm not interested in marking numbers but its cdr is seven.

446
00:27:08,700 --> 00:27:10,450
So I can mark that.

447
00:27:10,450 --> 00:27:12,260
Bang.

448
00:27:12,260 --> 00:27:13,675
Seven is the empty list, 

449
00:27:13,675 --> 00:27:15,595
the only thing that references, 

450
00:27:15,595 --> 00:27:17,120
and it's got a number in its car.

451
00:27:17,120 --> 00:27:19,490
Not interesting.

452
00:27:19,490 --> 00:27:20,500
Well now let's go back here.

453
00:27:20,500 --> 00:27:21,650
I forgot about something.

454
00:27:21,650 --> 00:27:22,840
Two.

455
00:27:22,840 --> 00:27:25,425
See in other words, if I'm looking at cell one, 

456
00:27:25,425 --> 00:27:30,370
cell one contains a two right over here.

457
00:27:30,370 --> 00:27:31,730
A reference to two.

458
00:27:31,730 --> 00:27:35,700
That means I should go mark two.

459
00:27:35,700 --> 00:27:37,140
Bang.

460
00:27:37,140 --> 00:27:38,960
Two contains a reference to four.

461
00:27:38,960 --> 00:27:41,489
It's got a number in its car, I'm not interested in that, 

462
00:27:41,489 --> 00:27:43,780
so I'm going to go mark that.

463
00:27:43,780 --> 00:27:46,750
Four refers to seven through its car, 

464
00:27:46,750 --> 00:27:48,475
and is empty in its cdr, 

465
00:27:48,475 --> 00:27:51,400
but I've already marked that one so I don't have to mark it again.

466
00:27:51,400 --> 00:27:55,000
This is all the accessible structure from that place.

467
00:27:55,000 --> 00:27:58,710
Simple recursive mark algorithm.

468
00:27:58,710 --> 00:28:01,900
Now there are some unhappinesses about that algorithm, 

469
00:28:01,900 --> 00:28:04,920
and we can worry about that a second.

470
00:28:04,920 --> 00:28:09,625
But basically you'll see that all the things that have not been marked 

471
00:28:09,625 --> 00:28:14,220
are places that are free, and I could recycle.

472
00:28:14,220 --> 00:28:17,945
So the next stage after that is going to be to scan through all of my memory, 

473
00:28:17,945 --> 00:28:21,180
looking for things that are not marked.

474
00:28:21,180 --> 00:28:23,225
Every time I come across a marked thing I unmark it, 

475
00:28:23,225 --> 00:28:26,297
and every time I come across an unmarked thing 

476
00:28:26,297 --> 00:28:28,770
I'm going to link it together in my free list.

477
00:28:28,770 --> 00:28:32,120
Classic, very simple algorithm.

478
00:28:32,120 --> 00:28:33,840
So let's see.

479
00:28:33,840 --> 00:28:34,770
Is that very simple?

480
00:28:34,770 --> 00:28:35,570
Yes it is.

481
00:28:35,570 --> 00:28:38,009
I'm not going to go through the code in any detail, 

482
00:28:38,009 --> 00:28:40,090
but I just want to show you about how long it is.

483
00:28:40,090 --> 00:28:42,490
Let's look at the mark phase.

484
00:28:42,490 --> 00:28:45,060
Here's the first part of the mark phase.

485
00:28:45,060 --> 00:28:46,425
We pick up the root.

486
00:28:46,500 --> 00:28:47,525
We're going to do some

487
00:28:47,675 --> 00:28:52,380
We're going to use that as a recursive procedure call.

488
00:28:52,380 --> 00:28:54,775
We're going to sweep from there, 

489
00:28:54,775 --> 00:28:57,380
after when we're done with marking.

490
00:28:57,380 --> 00:29:03,075
And then we're going to do a little couple of instructions that do this checking out on the marks and changing the marks and things like that, 

491
00:29:03,075 --> 00:29:05,500
according to the algorithm I've just shown you.

492
00:29:05,500 --> 00:29:06,470
It comes out here.

493
00:29:06,470 --> 00:29:07,875
You have to mark the cars of things 

494
00:29:07,875 --> 00:29:10,660
and you also have to be able to mark the cdrs of things.

495
00:29:10,660 --> 00:29:14,370
That's the entire mark phase.

496
00:29:14,370 --> 00:29:16,590
I'll just tell you a little story about this.

497
00:29:16,590 --> 00:29:20,937
The old DEC PDP-6 computer, 

498
00:29:20,937 --> 00:29:26,740
this was the way that the mark-sweep garbage collection, as it was, was written.

499
00:29:26,740 --> 00:29:29,257
The program was so small 

500
00:29:29,257 --> 00:29:32,201
that with the data that it needed, 

501
00:29:32,201 --> 00:29:36,169
with the registers that it needed to manipulate the memory, 

502
00:29:36,169 --> 00:29:39,280
it fit into the fast registers of the machine, which were 16.

503
00:29:39,280 --> 00:29:39,800
The whole program.

504
00:29:39,800 --> 00:29:43,170
And you could execute instructions in the fast registers.

505
00:29:43,170 --> 00:29:45,850
So it's an extremely small program, 

506
00:29:45,850 --> 00:29:48,870
and it could run very fast.

507
00:29:48,870 --> 00:29:51,610
Now unfortunately, of course, 

508
00:29:51,610 --> 00:29:54,800
this program, because the fact that it's recursive 

509
00:29:54,800 --> 00:29:59,216
in the way that you do something first and then you do something after that, 

510
00:29:59,216 --> 00:30:01,150
you have to work on the cars and then the cdrs, 

511
00:30:01,150 --> 00:30:03,410
it requires auxiliary memory.

512
00:30:03,410 --> 00:30:08,260
So Lisp systems-- those requires a stack for marking.

513
00:30:08,260 --> 00:30:11,575
Lisp systems that are built this way 

514
00:30:11,575 --> 00:30:14,425
have a limit to the depth of recursion you can have 

515
00:30:14,425 --> 00:30:17,817
in data structures in either the car or the cdr, 

516
00:30:17,817 --> 00:30:19,930
and that doesn't work very nicely.

517
00:30:19,930 --> 00:30:23,180
On the other hand, you never notice it if it's big enough.

518
00:30:23,180 --> 00:30:28,697
And that's certainly been the case for most Maclisp, for example, 

519
00:30:28,697 --> 00:30:33,560
which ran Macsyma where you could deal with expressions of thousands of elements long.

520
00:30:33,560 --> 00:30:36,825
These are algebraic expressions with thousand of terms. 

521
00:30:36,825 --> 00:30:39,490
And there's no problem with that.

522
00:30:39,490 --> 00:30:42,190
Such, the garbage collector does work.

523
00:30:42,190 --> 00:30:42,925
On the other hand, 

524
00:30:42,925 --> 00:30:46,800
there's a very clever modification to this algorithm, which I will not describe, 

525
00:30:46,800 --> 00:30:50,768
by Peter Deutsch and Schorr and Waite-- 

526
00:30:50,768 --> 00:30:55,380
Herb Schorr from IBM and Waite, who I don't know.

527
00:30:55,380 --> 00:30:56,675
That algorithm allows you to build- -

528
00:30:56,675 --> 00:31:00,500
 you do can do this without auxiliary memory, 

529
00:31:00,500 --> 00:31:02,975
by remembering as you walk the data structures 

530
00:31:02,975 --> 00:31:05,525
where you came from by reversing the pointers as you go down 

531
00:31:05,525 --> 00:31:07,520
and crawling up the reverse pointers as you go up. 

532
00:31:07,520 --> 00:31:09,130
It's a rather tricky algorithm.

533
00:31:09,130 --> 00:31:14,350
The first time you write it-- or in fact, the first three times you write it it has a terrible bug in it.

534
00:31:14,350 --> 00:31:18,110
And it's also rather slow, because it's complicated.

535
00:31:18,110 --> 00:31:20,850
It takes about six times as many memory references 

536
00:31:20,850 --> 00:31:24,580
to do the sorts of things that we're talking about.

537
00:31:24,580 --> 00:31:27,500
Well now once I've done this marking phase, 

538
00:31:27,500 --> 00:31:31,510
and I get into a position where things look like this, let's look-- yes.

539
00:31:31,510 --> 00:31:35,590
Here we have the mark done, just as I did it.

540
00:31:35,590 --> 00:31:37,330
Now we have to perform the sweep phase.

541
00:31:37,330 --> 00:31:39,820
And I described to you what this sweep is like.

542
00:31:39,820 --> 00:31:42,348
I'm going to walk down from one end of memory or the other, 

543
00:31:42,348 --> 00:31:43,628
I don't care where, 

544
00:31:43,628 --> 00:31:46,836
scanning every cell that's in the memory.

545
00:31:47,175 --> 00:31:49,207
And as I scan these cells, 

546
00:31:49,207 --> 00:31:51,950
I'm going to link them together, if they are free, 

547
00:31:51,950 --> 00:31:53,150
into the free list. 

548
00:31:53,150 --> 00:31:57,500
And if they're not free, I'm going to unmark them so the marks become zero.

549
00:31:57,500 --> 00:31:58,700
And in fact what I get-- 

550
00:31:58,700 --> 00:32:00,460
well the program is not very complicated.

551
00:32:00,460 --> 00:32:02,780
It looks sort of like this-- it's a little longer.

552
00:32:02,780 --> 00:32:04,820
Here's the first piece of it.

553
00:32:04,820 --> 00:32:06,710
This one's coming down from the top of memory.

554
00:32:06,710 --> 00:32:09,580
I don't want you to try to understand this at this point.

555
00:32:09,580 --> 00:32:11,030
It's rather simple.

556
00:32:11,030 --> 00:32:13,075
It's a very simple algorithm, 

557
00:32:13,075 --> 00:32:15,970
but there's pieces of it that just sort of look like this.

558
00:32:15,970 --> 00:32:18,600
They're all sort of obvious.

559
00:32:18,600 --> 00:32:20,307
And after we've done the sweep, 

560
00:32:20,307 --> 00:32:22,310
we get an answer that looks like that.

561
00:32:25,330 --> 00:32:29,590
Now there are some disadvantages with mark-sweep algorithms of this sort.

562
00:32:29,590 --> 00:32:31,450
Serious ones.

563
00:32:31,450 --> 00:32:36,498
One important disadvantage is that your memories get larger and larger.

564
00:32:36,826 --> 00:32:41,370
As you say, address spaces get larger and larger, you're willing to represent more and more stuff, 

565
00:32:41,370 --> 00:32:46,360
then it gets very costly to scan all of memory.

566
00:32:46,360 --> 00:32:50,490
What you'd really like to do is only scan useful stuff.

567
00:32:50,490 --> 00:32:52,075
It would even be better 

568
00:32:52,075 --> 00:32:58,283
if you realized that some stuff was known to be good and useful, 

569
00:32:58,283 --> 00:33:00,370
and you don't have to look at it more than once or twice.

570
00:33:00,370 --> 00:33:01,550
Or very rarely.

571
00:33:01,550 --> 00:33:05,003
Whereas other stuff that you're not so sure about, 

572
00:33:05,003 --> 00:33:09,931
you can look at more detail every time you want to do this, 

573
00:33:09,931 --> 00:33:11,910
want to garbage collect.

574
00:33:11,910 --> 00:33:15,660
Well there are algorithms that are organized in this way.

575
00:33:15,660 --> 00:33:18,282
Let me tell you about a famous old algorithm 

576
00:33:18,282 --> 00:33:22,800
which allows you only look at the part of memory which is known to be useful.

577
00:33:22,800 --> 00:33:26,310
And which happens to be the fastest known garbage collector algorithm.

578
00:33:26,310 --> 00:33:30,150
This is the Minsky-Feinchel-Yochelson garbage collector algorithm.

579
00:33:30,150 --> 00:33:36,525
It was invented by Minsky in 1961 or '60 or something, 

580
00:33:36,525 --> 00:33:40,125
for the RLE PDP-1 Lisp, 

581
00:33:40,125 --> 00:33:48,480
which had 4,096 words of list memory, and a drum.

582
00:33:48,480 --> 00:33:53,050
And the whole idea was to garbage collect this terrible memory.

583
00:33:53,050 --> 00:33:56,200
What Minsky realized was the easiest way to do this 

584
00:33:56,200 --> 00:33:58,475
is to scan the memory in the same sense, 

585
00:33:58,475 --> 00:34:01,575
walking the good structure, 

586
00:34:01,575 --> 00:34:06,350
copying it out into the drum, compacted.

587
00:34:06,350 --> 00:34:09,127
And then when we were done copying it all out, 

588
00:34:09,127 --> 00:34:12,300
then you swap that back into your memory.

589
00:34:12,300 --> 00:34:17,030
Now whether or you not use a drum, or another piece of memory, or something like that isn't important.

590
00:34:17,030 --> 00:34:20,350
In fact, I don't think people use drums anymore for anything.

591
00:34:20,350 --> 00:34:25,425
But this algorithm basically depends upon having 

592
00:34:25,425 --> 00:34:30,270
about twice as much address space as you're actually using.

593
00:34:30,270 --> 00:34:33,125
And so what you have is some, initially, 

594
00:34:33,125 --> 00:34:37,110
some mixture of useful data and garbage.

595
00:34:37,110 --> 00:34:38,560
So this is called fromspace.

596
00:34:45,179 --> 00:34:47,800
And this is a mixture of crud.

597
00:34:47,800 --> 00:34:52,000
Some of it's important and some of it isn't.

598
00:34:52,000 --> 00:34:55,775
Now there's another place which is hopefully big enough, 

599
00:34:55,775 --> 00:34:58,240
if we recall, tospace, which is where we're copying to.

600
00:35:01,590 --> 00:35:02,600
And what happens is-- 

601
00:35:02,600 --> 00:35:04,970
and I'm not going to go through this detail.

602
00:35:04,970 --> 00:35:07,590
It's in our book quite explicitly.

603
00:35:07,590 --> 00:35:11,030
There's a root point where you start from.

604
00:35:11,030 --> 00:35:14,600
And the idea is that you start with the root.

605
00:35:14,600 --> 00:35:17,832
You copy the first thing you see, 

606
00:35:17,832 --> 00:35:19,752
the first thing that the root points at, 

607
00:35:19,752 --> 00:35:22,810
to the beginning of tospace.

608
00:35:22,810 --> 00:35:27,560
The first thing is a pair or something like, a data structure.

609
00:35:27,560 --> 00:35:31,775
You then also leave behind a broken heart saying, 

610
00:35:31,775 --> 00:35:35,743
I moved this object from here to here, 

611
00:35:35,743 --> 00:35:37,800
giving the place where it moved to.

612
00:35:37,800 --> 00:35:39,650
This is called a broken heart because 

613
00:35:39,650 --> 00:35:43,825
a friend of mine who implemented one of these in 1966 

614
00:35:43,825 --> 00:35:46,760
was a very romantic character and called it a broken heart.

615
00:35:49,580 --> 00:35:51,150
But in any case, 

616
00:35:51,150 --> 00:35:52,942
the next thing you do 

617
00:35:52,942 --> 00:35:55,175
is now you have a new free pointer which is here, 

618
00:35:55,175 --> 00:35:57,840
and you start scanning.

619
00:35:57,840 --> 00:36:00,235
You scan this data structure you just copied.

620
00:36:00,551 --> 00:36:02,195
And every time you encounter a pointer in it, 

621
00:36:02,195 --> 00:36:04,000
you treat it as if it was the root pointer here.

622
00:36:04,000 --> 00:36:05,170
Oh, I'm sorry.

623
00:36:05,170 --> 00:36:09,220
The other thing you do is you now move the root pointer to there.

624
00:36:09,220 --> 00:36:10,175
So now you scan this, 

625
00:36:10,175 --> 00:36:14,110
and everything you see you treat as it were the root pointer.

626
00:36:14,110 --> 00:36:15,450
So if you see something, 

627
00:36:15,450 --> 00:36:18,510
well it points up into there somewhere.

628
00:36:18,510 --> 00:36:21,780
Is it pointing at a thing which you've not copied yet?

629
00:36:21,780 --> 00:36:23,880
Is there a broken heart there?

630
00:36:23,880 --> 00:36:26,202
If there's a broken heart there and it's something you have copied, 

631
00:36:26,202 --> 00:36:29,825
you've just replaced this pointer with the thing a broken heart points at.

632
00:36:29,825 --> 00:36:32,125
If this thing has not been copied, 

633
00:36:32,125 --> 00:36:34,430
you copy it to the next place over here.

634
00:36:34,430 --> 00:36:37,053
Move your free pointer over here, 

635
00:36:37,053 --> 00:36:43,670
and then leave a broken heart behind and scan.

636
00:36:43,670 --> 00:36:46,825
And eventually when the scant pointer hits the free pointer, 

637
00:36:46,825 --> 00:36:50,140
everything in memory has been copied.

638
00:36:50,140 --> 00:36:52,075
And then there's a whole bunch of empty space up here, 

639
00:36:52,075 --> 00:36:54,470
which you could either make into a free list, if that's what you want to do.

640
00:36:54,470 --> 00:36:56,270
But generally you don't in this kind of system.

641
00:36:56,270 --> 00:37:00,910
In this system you sequentially allocate your memory.

642
00:37:00,910 --> 00:37:02,975
That is a very, very nice algorithm, 

643
00:37:02,975 --> 00:37:06,790
and sort of the one we use in the scheme that you've been using.

644
00:37:06,790 --> 00:37:09,475
And it's expected-- 

645
00:37:09,475 --> 00:37:12,400
I believe no one has found a faster algorithm than that.

646
00:37:12,400 --> 00:37:14,850
There are very simple modifications to this algorithm 

647
00:37:14,850 --> 00:37:17,175
invented by Henry Baker 

648
00:37:17,175 --> 00:37:20,311
which allow one to run this algorithm in real time, 

649
00:37:20,311 --> 00:37:22,010
meaning you don't have to stop to garbage collect.

650
00:37:22,010 --> 00:37:26,327
But you could interleave the consing that the machine does when its running 

651
00:37:26,327 --> 00:37:28,887
with steps of the garbage collection process, 

652
00:37:28,887 --> 00:37:31,200
so that the garbage collector's distributed, 

653
00:37:31,200 --> 00:37:32,416
and the machine doesn't have to stop, 

654
00:37:32,416 --> 00:37:34,640
and garbage collecting can start.

655
00:37:34,640 --> 00:37:38,900
Of course in the case of machines with virtual memory

656
00:37:38,900 --> 00:37:41,509
 where a lot of it is in inaccessible places, 

657
00:37:41,509 --> 00:37:44,460
this becomes a very expensive process.

658
00:37:44,460 --> 00:37:49,190
And there have been numerous attempts to make this much better.

659
00:37:49,190 --> 00:37:52,645
There is a nice paper, for those of you who are interested, 

660
00:37:52,645 --> 00:37:54,650
by Moon and other people 

661
00:37:54,650 --> 00:37:59,514
which describes a modification to the incremental Minsky-Feinchel-Yochelson algorithm, 

662
00:37:59,514 --> 00:38:01,425
and modification the Baker algorithm 

663
00:38:01,425 --> 00:38:08,340
which is more efficient for virtual memory systems.

664
00:38:08,340 --> 00:38:12,840
Well I think now the mystery to this is sort of gone.

665
00:38:12,840 --> 00:38:14,090
And I'd like to see if there are any questions.

666
00:38:19,780 --> 00:38:20,810
Yes.

667
00:38:20,810 --> 00:38:25,937
AUDIENCE: I saw one of you run the garbage collector on the systems upstairs, 

668
00:38:25,937 --> 00:38:28,497
and it seemed to me to run extremely fast. 

669
00:38:28,497 --> 00:38:31,880
Did the whole thing take-- does it sweep through all of memory?

670
00:38:31,880 --> 00:38:32,510
PROFESSOR: No.

671
00:38:32,510 --> 00:38:37,320
It swept through exactly what was needed to copy the useful structure.

672
00:38:37,320 --> 00:38:39,300
It's a copying collector.

673
00:38:39,300 --> 00:38:45,050
And it is very fast. On the whole, I suppose to copy-- 

674
00:38:45,050 --> 00:38:48,442
in a Bobcat-- to copy, 

675
00:38:48,442 --> 00:38:56,800
I think, a three megabyte thing or something is less than a second, real time.

676
00:38:56,800 --> 00:38:58,625
Really, these are very small programs. 

677
00:38:58,625 --> 00:39:02,913
One thing you should realise is that 

678
00:39:02,913 --> 00:39:05,400
garbage collectors have to be small.

679
00:39:05,400 --> 00:39:07,905
Not because they have to be fast, 

680
00:39:07,905 --> 00:39:11,340
but because no one can debug a complicated garbage collector.

681
00:39:11,340 --> 00:39:14,049
A garbage collector, if it doesn't work, 

682
00:39:14,049 --> 00:39:18,350
will trash your memory in such a way that you cannot figure out what the hell happened.

683
00:39:18,350 --> 00:39:20,660
You need an audit trail.

684
00:39:20,660 --> 00:39:23,740
Because it rearranges everything, and how do you know what happened there?

685
00:39:23,740 --> 00:39:26,925
So this is the only kind of program that 

686
00:39:26,925 --> 00:39:31,970
it really, seriously matters if you stare at it long enough so you believe that it works.

687
00:39:31,970 --> 00:39:35,100
And sort of prove it to yourself.

688
00:39:35,100 --> 00:39:36,940
So there's no way to debug it.

689
00:39:36,940 --> 00:39:41,690
And that takes it being small enough so you can hold it in your head.

690
00:39:41,690 --> 00:39:45,020
Garbage collectors are special in this way.

691
00:39:45,020 --> 00:39:46,775
So every reasonable garbage collector has gotten small, 

692
00:39:46,775 --> 00:39:52,050
and generally small programs are fast. 

693
00:39:52,050 --> 00:39:52,430
Yes.

694
00:39:52,430 --> 00:39:54,510
AUDIENCE: Can you repeat the name of this technique once again?

695
00:39:54,510 --> 00:39:58,420
PROFESSOR: That's the Minsky-Feinchel-Yochelson garbage collector.

696
00:39:58,420 --> 00:39:59,340
AUDIENCE: You got that?

697
00:39:59,340 --> 00:40:02,210
PROFESSOR: Minsky invented it in '61 for the RLE PDP-1.

698
00:40:02,210 --> 00:40:06,450
A version of it was developed and elaborated 

699
00:40:06,450 --> 00:40:11,378
to be used in Multics Maclisp by Feinchel and Yochelson 

700
00:40:11,378 --> 00:40:19,570
in somewhere around 1968 or '69.

701
00:40:19,570 --> 00:40:20,650
OK.

702
00:40:20,650 --> 00:40:22,640
Let's take a break.

703
00:40:22,640 --> 00:40:24,184
[MUSIC: "JESU, JOY OF MAN'S DESIRING" BY JOHANN SEBASTIAN BACH]

704
00:41:17,310 --> 00:41:26,740
PROFESSOR: Well we've come to the end of this subject, and we've already shown you a universal machine which is down to evaluator.

705
00:41:26,740 --> 00:41:30,420
It's down to the level of detail you could imagine you could make one.

706
00:41:30,420 --> 00:41:39,180
This is a particular implementation of Lisp, built on one of those scheme chips that was talked about yesterday, sitting over here.

707
00:41:39,180 --> 00:41:45,010
This is mostly interface to somebody's memory with a little bit of timing and other such stuff.

708
00:41:45,010 --> 00:41:50,610
But this fellow actually ran Lisp at a fairly reasonable rate, as interpretive.

709
00:41:50,610 --> 00:41:56,500
It ran Lisp as fast as a DEC PDP-10 back in 1979.

710
00:41:56,500 --> 00:41:59,870
And so it's gotten pretty hardware.

711
00:41:59,870 --> 00:42:02,470
Pretty concrete.

712
00:42:02,470 --> 00:42:07,370
We've also downed you a bit with the things you can compute.

713
00:42:07,370 --> 00:42:11,850
But is it the case that there are things we can't compute?

714
00:42:11,850 --> 00:42:18,190
And so I'd like to end this with showing you some things that you'd like be able to compute that you can't.

715
00:42:18,190 --> 00:42:22,720
The answer is yes, there are things you can't compute.

716
00:42:22,720 --> 00:42:34,630
For example, something you'd really like is-- if you're writing [UNINTELLIGIBLE], you'd like a program that would check that the thing you're going to do will work.

717
00:42:34,630 --> 00:42:36,080
Wouldn't that be nice?

718
00:42:36,080 --> 00:42:43,190
You'd like something that would catch infinite loops, for example, in programs that were written by users.

719
00:42:43,190 --> 00:42:50,990
But in general you can't write such a program that will read any program and determine whether or not it's an infinite loop.

720
00:42:50,990 --> 00:42:51,685
Let me show you that.

721
00:42:51,685 --> 00:42:53,340
It's a little bit of a minor mathematics.

722
00:42:58,780 --> 00:43:02,620
Let's imagine that we just had a mathematical function before we start.

723
00:43:02,620 --> 00:43:14,230
And there is one, called s, which takes a procedure and its argument, a.

724
00:43:19,320 --> 00:43:26,632
And what s does is it determines whether or not it's safe to run p on a.

725
00:43:26,632 --> 00:43:45,330
And what I mean by that is this: it's true if p applied to a will converge to a value without an error.

726
00:43:52,365 --> 00:44:06,890
And it's false if p of a loops forever or makes an error.

727
00:44:15,000 --> 00:44:18,780
Now that's surely a function.

728
00:44:18,780 --> 00:44:28,440
There is some for every procedure and for every argument you could give it that is either true or false that it converges without making an error.

729
00:44:28,440 --> 00:44:31,770
And you could make a giant table of them.

730
00:44:31,770 --> 00:44:37,430
But the question is, can you write a procedure that compute the values of this function?

731
00:44:37,430 --> 00:44:39,720
Well let's assume that we can.

732
00:44:39,720 --> 00:44:59,990
Suppose that we have a procedure called "safe" that computes the value of s.

733
00:45:12,170 --> 00:45:19,760
Now I'm going to show you by several methods that you can't do this.

734
00:45:19,760 --> 00:45:23,810
The easiest one, or the first one, let's define a procedure called diag1.

735
00:45:23,810 --> 00:45:44,780
Given that we have safe, we can define diag1 to be the procedure of one argument, p, which has the following properties.

736
00:45:44,780 --> 00:45:55,870
If if it's safe to apply p to itself, then I wish to have an infinite loop.

737
00:45:59,330 --> 00:46:00,715
Otherwise I'm going to return 3.

738
00:46:03,680 --> 00:46:04,470
Remember it was 42.

739
00:46:04,470 --> 00:46:07,060
What's the answer to the big question?

740
00:46:07,060 --> 00:46:08,525
Where of course we know what an infinite loop is.

741
00:46:12,050 --> 00:46:18,430
Infinite loop, to be a procedure of no arguments, which is that nice lambda calculus loop.

742
00:46:18,430 --> 00:46:24,680
Lambda of x, x of x, applied to lambda of x, x of x.

743
00:46:24,680 --> 00:46:26,550
So there's nothing left to the imagination here.

744
00:46:29,830 --> 00:46:32,500
Well let's see what the story is.

745
00:46:32,500 --> 00:46:43,180
I'm supposing it's the case that we worry about the procedure called diag1 applied to diag1.

746
00:46:45,860 --> 00:46:49,970
Well what could it possibly be?

747
00:46:49,970 --> 00:46:51,390
Well I don't know.

748
00:46:51,390 --> 00:46:57,310
We're going to substitute diag1 for p in the body here.

749
00:46:57,310 --> 00:47:00,220
Well is it safe to compute diag1 of diag1?

750
00:47:00,220 --> 00:47:00,780
I don't know.

751
00:47:00,780 --> 00:47:03,400
There are two possibilities.

752
00:47:03,400 --> 00:47:08,490
If it's safe to compute diag1 of diag1 that means it shouldn't loop.

753
00:47:08,490 --> 00:47:10,560
That means I go to here, but then I produce an infinite loop.

754
00:47:10,560 --> 00:47:12,210
So it can't be safe.

755
00:47:12,210 --> 00:47:16,020
But if it's not safe to compute diag1 of diag1 then the answer to this is 3.

756
00:47:16,020 --> 00:47:20,530
But that's diag1 of diag1, so it had to be safe.

757
00:47:20,530 --> 00:47:27,470
So therefore by contradiction you cannot produce safe.

758
00:47:27,470 --> 00:47:32,820
For those of you who were boggled by that one I'm going to say it again, in a different way.

759
00:47:32,820 --> 00:47:35,530
Listen to one more alternative.

760
00:47:35,530 --> 00:47:36,780
Let's define diag2.

761
00:47:39,840 --> 00:47:45,260
These are named diag because of Cantor's diagonal argument.

762
00:47:45,260 --> 00:48:00,190
These are instances of a famous argument which was originally used by Cantor in the late part of the last century to prove that the real numbers were not countable, that there are too many real numbers to be counted by integers.

763
00:48:00,190 --> 00:48:05,260
That there are more points on a line, for example, than there are counting numbers.

764
00:48:05,260 --> 00:48:08,440
It may or may not be obvious, and I don't want to get into that now.

765
00:48:10,900 --> 00:48:15,820
But diag2 is again a procedure of one argument p.

766
00:48:15,820 --> 00:48:38,960
It's almost the same as the previous one, which is, if it's safe to compute p on p, then I'm going to produce-- then I want to compute some other things other than p of p.

767
00:48:38,960 --> 00:48:40,210
Otherwise I'm going to put out false.

768
00:48:43,600 --> 00:48:48,880
Where other then it says, whatever p of p, I'm going to put out something else.

769
00:48:48,880 --> 00:48:53,890
I can give you an example of a definition of other than which I think works.

770
00:48:53,890 --> 00:48:55,640
Let's see.

771
00:48:55,640 --> 00:48:56,330
Yes.

772
00:48:56,330 --> 00:49:15,720
Where other than be a procedure of one argument x which says, if its eq x to, say, quote a, then the answer is quote b.

773
00:49:15,720 --> 00:49:16,970
Otherwise it's quote a.

774
00:49:20,090 --> 00:49:25,350
That always produces something which is not what its argument is.

775
00:49:25,350 --> 00:49:26,540
That's all it is.

776
00:49:26,540 --> 00:49:28,250
That's all I wanted.

777
00:49:28,250 --> 00:49:30,640
Well now let's consider this one, diag2 of diag2.

778
00:49:38,220 --> 00:49:39,560
Well look.

779
00:49:39,560 --> 00:49:47,470
This only does something dangerous, like calling p of p, if it's safe to do so.

780
00:49:47,470 --> 00:49:57,225
So if safe defined at all, if you can define such a procedure, safe, then this procedure is always defined and therefore safe on any inputs.

781
00:50:01,540 --> 00:50:11,770
So diag2 of diag2 must reduce to other than diag2 of diag2.

782
00:50:15,496 --> 00:50:22,950
And that doesn't make sense, so we have a contradiction, and therefore we can't define safe.

783
00:50:22,950 --> 00:50:32,260
I just waned to do that twice, slightly differently, so you wouldn't feel that the first one was a trick.

784
00:50:32,260 --> 00:50:37,300
They may be both tricks, but they're at least slightly different.

785
00:50:37,300 --> 00:50:40,080
So I suppose that pretty much wraps it up.

786
00:50:40,080 --> 00:50:46,720
I've just proved what we call the halting theorem, and I suppose with that we're going to halt.

787
00:50:46,720 --> 00:50:47,970
I hope you have a good time.

788
00:50:50,900 --> 00:50:53,300
Are there any questions?

789
00:50:53,300 --> 00:50:53,810
Yes.

790
00:50:53,810 --> 00:50:56,940
AUDIENCE: What is the value of s of diag1?

791
00:50:56,940 --> 00:50:57,430
PROFESSOR: Of what?

792
00:50:57,430 --> 00:51:00,120
AUDIENCE: S of diag1.

793
00:51:00,120 --> 00:51:02,620
If you said s is a function and we can [INTERPOSING VOICES]

794
00:51:02,620 --> 00:51:03,870
PROFESSOR: Oh, I don't know.

795
00:51:03,870 --> 00:51:04,350
I don't know.

796
00:51:04,350 --> 00:51:06,850
It's a function, but I don't know how to compute it.

797
00:51:06,850 --> 00:51:08,610
I can't do it.

798
00:51:08,610 --> 00:51:11,530
I'm just a machine, too.

799
00:51:11,530 --> 00:51:12,210
Right?

800
00:51:12,210 --> 00:51:18,580
There's no machine that in principle-- it might be that in that particular case you just asked, with some thinking I could figure it out.

801
00:51:18,580 --> 00:51:23,780
But in general I can't compute the value of s any better than any other machine can.

802
00:51:23,780 --> 00:51:29,580
There is such a function, it's just that no machine can be built to compute it.

803
00:51:29,580 --> 00:51:35,350
Now there's a way of saying that that should not be surprising.

804
00:51:35,350 --> 00:51:44,600
Going through this-- I mean, I don't have time to do this here, but the number of functions is very large.

805
00:51:44,600 --> 00:51:54,720
If there's a certain number of answers possible and a certain number of inputs possible, then it's the number of answers raised to the number inputs is the number of possible functions.

806
00:51:54,720 --> 00:51:55,970
On one variable.

807
00:51:58,150 --> 00:52:05,480
Now that's always bigger than the thing you're raising to, the exponent.

808
00:52:05,480 --> 00:52:17,840
The number of functions is larger than the number of programs that one can write, by an infinity counting argument.

809
00:52:17,840 --> 00:52:19,475
And it's much larger.

810
00:52:19,475 --> 00:52:26,280
So there must be a lot of functions that can't be computed by programs.

811
00:52:26,280 --> 00:52:30,640
AUDIENCE: A few moments ago you were talking about specifications and automatic generation of solutions.

812
00:52:30,640 --> 00:52:33,360
Do you see any steps between specifications and solutions?

813
00:52:37,250 --> 00:52:38,720
PROFESSOR: Steps between.

814
00:52:38,720 --> 00:52:45,205
You mean, you're saying, how you go about constructing devices given that have specifications for the device?

815
00:52:45,205 --> 00:52:45,500
Sure.

816
00:52:45,500 --> 00:52:52,430
AUDIENCE: There's a lot of software engineering that goes through specifications through many layers of design and then implementation.

817
00:52:52,430 --> 00:52:52,850
PROFESSOR: Yes?

818
00:52:52,850 --> 00:52:55,600
AUDIENCE: I was curious if you think that's realistic.

819
00:52:55,600 --> 00:52:58,100
PROFESSOR: Well I think that some of it's realistic and some of it isn't.

820
00:52:58,100 --> 00:53:07,160
I mean, surely if I want to build an electrical filter and I have a rather interesting possibility.

821
00:53:07,160 --> 00:53:19,906
Supposing I want to build a thing that matches some power output to the radio transmitter, to some antenna.

822
00:53:19,906 --> 00:53:23,230
And I'm really out of this power-- it's output tube out here.

823
00:53:23,230 --> 00:53:25,920
And the problem is that they have different impedances.

824
00:53:25,920 --> 00:53:27,550
I want them to match the impedances.

825
00:53:27,550 --> 00:53:32,780
I also want to make a filter in there which is going to get rid of some harmonic radiation.

826
00:53:32,780 --> 00:53:38,860
Well one old-fashioned technique for doing this is called image impedances, or something like that.

827
00:53:38,860 --> 00:53:43,300
And what you do is you say you have a basic module called an L-section.

828
00:53:43,300 --> 00:53:44,550
Looks like this.

829
00:53:47,080 --> 00:54:02,110
If I happen to connect this to some resistance, r, and if I make this impedance x, xl, and if it happens to be q times r, then this produces a low pass filter with a q square plus one impedance match.

830
00:54:02,110 --> 00:54:03,120
Just what I need.

831
00:54:03,120 --> 00:54:06,510
Because now I can take two of these, hook them together like this.

832
00:54:11,660 --> 00:54:18,290
OK, and I take another one and I'll hook them together like that.

833
00:54:18,290 --> 00:54:20,320
And I have two L-sections hooked together.

834
00:54:20,320 --> 00:54:25,530
And this will step the impedance down to one that I know, and this will step it up to one I know.

835
00:54:25,530 --> 00:54:28,090
Each of these is a low pass filter getting rid of some harmonics.

836
00:54:28,090 --> 00:54:30,270
It's good filter, it's called a pie-section filter.

837
00:54:30,270 --> 00:54:31,700
Great.

838
00:54:31,700 --> 00:54:38,620
Except for the fact that in doing what I just did, I've made a terrible inefficiency in this system.

839
00:54:38,620 --> 00:54:41,620
I've made two coils where I should have made one.

840
00:54:41,620 --> 00:54:55,350
And the problem with most software engineering art is that there's no mechanism, other than peephole optimization and compilers, for getting rid of the redundant parts that are constructed when doing top down design.

841
00:54:55,350 --> 00:55:01,110
It's even worse, there are lots of very important structures that you can't construct at all this way.

842
00:55:01,110 --> 00:55:05,710
So I think that the standard top down design is a rather shallow business.

843
00:55:05,710 --> 00:55:08,315
Doesn't really capture what people want to do in design.

844
00:55:08,315 --> 00:55:10,100
I'll give you another electrical example.

845
00:55:10,100 --> 00:55:17,220
Electrical examples are so much clearer than computational examples, because computation examples require a certain degree of complexity to explain them.

846
00:55:17,220 --> 00:55:27,530
But one of my favorite examples in the electrical world is how would I ever come up with the output stage of this inter-stage connection in an IF amplifier.

847
00:55:27,530 --> 00:55:32,410
It's a little transistor here, and let's see.

848
00:55:32,410 --> 00:55:44,850
Well I'm going to have a tank, and I'm going to hook this up to, say, I'm going to link-couple that to the input of the next stage.

849
00:55:44,850 --> 00:55:53,170
Here's a perfectly plausible plan-- well except for the fact that since I put that going up I should make that going that way.

850
00:55:53,170 --> 00:55:57,270
Here's a perfectly plausible plan for a-- no I shouldn't.

851
00:55:57,270 --> 00:55:57,940
I'm dumb.

852
00:55:57,940 --> 00:55:59,690
Excuse me.

853
00:55:59,690 --> 00:56:00,730
Doesn't matter.

854
00:56:00,730 --> 00:56:01,540
The point is [UNINTELLIGIBLE]

855
00:56:01,540 --> 00:56:02,560
plan for a couple [UNINTELLIGIBLE]

856
00:56:02,560 --> 00:56:04,590
stages together.

857
00:56:04,590 --> 00:56:07,620
Now what the problem is is what's this hierarchically?

858
00:56:07,620 --> 00:56:09,480
It's not one thing.

859
00:56:09,480 --> 00:56:11,990
Hierarchically it doesn't make any sense at all.

860
00:56:11,990 --> 00:56:26,460
It's the inductance of a tuned circuit, it's the primary of a transformer, and it's also the DC path by which bias conditions get to the collector of that transistor.

861
00:56:26,460 --> 00:56:34,530
And there's no simple top-down design that's going to produce a structure like that with so many overlapping uses for a particular thing.

862
00:56:34,530 --> 00:56:44,950
Playing Scrabble, where you have to do triple word scores, or whatever, is not so easy in top-down design strategy.

863
00:56:44,950 --> 00:56:52,140
Yet most of real engineering is based on getting the most oomph for effort.

864
00:56:52,140 --> 00:56:54,860
And that's what you're seeing here.

865
00:56:54,860 --> 00:56:55,550
Yeah?

866
00:56:55,550 --> 00:56:56,810
AUDIENCE: Is this the last question?

867
00:57:00,282 --> 00:57:18,640
[LAUGHTER]

868
00:57:18,640 --> 00:57:19,890
PROFESSOR: Apparently so.

869
00:57:23,240 --> 00:57:26,092
Thank you.

870
00:57:26,092 --> 00:57:39,040
[APPLAUSE]

871
00:57:39,040 --> 00:57:40,633
[MUSIC-- "JESU, JOY OF MAN'S DESIRING" BY JOHANN SEBASTIAN BACH]

